# TUM_ri â€” Reinforcement Learning for Robotic Locomotion

This repository contains code and documentation supporting research on applying **Reinforcement Learning (RL)** algorithms for **motion planning and locomotion** on legged robots â€” specifically **hexapod** and **quadruped** platforms. The work evolved from simulations using PyBullet to custom hardware design and realâ€‘world testing.

---

## ğŸš€ Project Overview

The goal of this research is to develop robust locomotion strategies using reinforcement learning that can be transferred from simulation environments to physical robots.

Main contributions include:

- A **simulated hexapod locomotion framework** using PyBullet.
- Custom design and development of a **quadruped robot** body.
- Code and tools to train, evaluate, and analyze RL policies for dynamic gait generation.
- Supporting data and visual results demonstrating locomotion performance.

---

## ğŸ§  Key Features

- ğŸ” **Reinforcement Learning (RL) integration** for adaptive robot motion control.
- ğŸœ **Hexapod simulation environment** for fast iteration.
- ğŸ¾ **Quadruped realâ€‘world implementation** in progress.
- ğŸ“Š Included media and documentation to illustrate motion results.
- ğŸ“ Contains thesis report and supporting materials.

---

## ğŸ“ Repository Structure

```
TUM_ri/
â”œâ”€â”€ gym_hexapod_zoo.py            # Main RL training and simulation code
â”œâ”€â”€ dachshund parts.zip           # 3D model assets / design files for robot
â”œâ”€â”€ rob-dynam_description.zip     # Robot dynamics or description data
â”œâ”€â”€ hexapod-movement-project.mp4  # Video of simulation/robot movement
â”œâ”€â”€ motor control.mov             # Another demonstration video
â”œâ”€â”€ thesis report (1).pdf         # Research thesis / final writeâ€‘up
â”œâ”€â”€ README.md                     # This file
â””â”€â”€ other assets / visuals        # Additional media
```

> â— *Note:* The main executable code relevant to training and running locomotion policies is in `gym_hexapod_zoo.py`. Other files include design assets, videos, and documentation.

---

## ğŸ›  Getting Started

### Prerequisites

Install the following on your machine:

- Python â‰¥ 3.7  
- PyBullet (`pip install pybullet`)  
- RL libraries such as Stable Baselines3 or custom frameworks  
- Standard scientific Python libraries (`numpy`, `gym`, etc.)

### Usage

1. **Clone this repository**

   ```bash
   git clone https://github.com/tejasms03/TUM_ri.git
   cd TUM_ri
   ```

2. **Install dependencies**

   ```bash
   pip install -r requirements.txt
   ```

3. **Run training/simulation**

   ```bash
   python gym_hexapod_zoo.py
   ```

   *Refer to inline comments in `gym_hexapod_zoo.py` for details on simulation configuration.*

---

## ğŸ“˜ Example

The `hexapod-movement-project.mp4` contains a demonstration of locomotion learned through reinforcement learning in simulation. Adjust parameters in the script to customize robot morphology, RL algorithms, or reward functions.

---

## ğŸ“„ Research & Documentation

Included in the repository:

- **`thesis report (1).pdf`** â€” detailed writeâ€‘up of problem statement, methodology, experiments, and conclusions.
- Design zip files for **robot assets** and **dynamics descriptions**.

---

## ğŸ¯ Future Directions

- Transfer learned policies from simulation to real quadruped hardware.
- Improve robustness to environment variations.
- Integrate additional sensors and perception for adaptive navigation.

---

## ğŸ§‘â€ğŸ’» Contributing

Contributions are welcome! To contribute:

1. Fork this repository.
2. Create your feature branch: `git checkout -b my-feature`
3. Commit changes: `git commit -m "Add feature"`
4. Push branch: `git push origin my-feature`
5. Open a Pull Request.

For major changes, please open an issue first for discussion.

---

## ğŸ“œ License

Currently not specified â€” you may want to add an openâ€‘source license such as MIT or BSD.

---

## â“ Questions

If you have questions about the project structure or research goals, feel free to open an issue or contact the maintainer.

